
<!DOCTYPE html>
<html lang="ja">
<head>

  
  <meta charset="UTF-8">
  <title>
    対話システムを作りたい！（実際はWikipediaのデータを取得して単語ベクトルを学習するまで） | hassaku&#39;s blog
  </title>


  
  <meta name="viewport" content="width=device-width,user-scalable=no,maximum-scale=1,initial-scale=1">

  
  <link rel="canonical" href="http://blog.hassaku-labs.com/post/dialogue_system1/"/>

  
  <link rel="stylesheet" href="http://blog.hassaku-labs.com/css/sanitize.css">
  <link rel="stylesheet" href="http://blog.hassaku-labs.com/css/responsive.css">
  <link rel="stylesheet" href="http://blog.hassaku-labs.com/css/highlight_monokai.css">
  <link rel="stylesheet" href="http://blog.hassaku-labs.com/css/theme.css">
  <link rel="stylesheet" href="http://blog.hassaku-labs.com/css/custom.css">
  
  
  <link href="http://blog.hassaku-labs.com/index.xml" rel="alternate" type="application/rss+xml" title="hassaku&#39;s blog" />
  <link href="http://blog.hassaku-labs.com/index.xml" rel="feed" type="application/rss+xml" title="hassaku&#39;s blog" />

  
  <script type="text/javascript">var switchTo5x=true;</script>
  <script type="text/javascript" src="https://ws.sharethis.com/button/buttons.js"></script>
  <script type="text/javascript">stLight.options({publisher: "2b9fffc6-b3fe-4988-a0ef-4f9dcce98eaa", doNotHash: true, doNotCopy: true, hashAddressBar: false});</script>


</head>



<body>
<div class="container">

  
  <header role="banner">
    <div class="row gutters">
      <div id="site-title" class="col span_6">
        <h1><a href="http://blog.hassaku-labs.com/">hassaku&#39;s blog</a></h1>
        <h2>no reason</h2>
      </div>
      <div id="social" class="col span_6">
        <ul>
          
          
          <li><a href="https://github.com/hassaku" target="_blank">GitHub</a></li>
          
        </ul>
      </div>
    </div>
  </header>


  
  <main id="single" role="main">
    <div class="article-header">
      <h1>対話システムを作りたい！（実際はWikipediaのデータを取得して単語ベクトルを学習するまで）</h1>
      <div class="meta">
        Apr 1, 2016 &nbsp;
        
          #<a href="http://blog.hassaku-labs.com/tags/nlp">NLP</a>&nbsp;
        
          #<a href="http://blog.hassaku-labs.com/tags/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0">対話システム</a>&nbsp;
        
      </div>
    </div>
    <article>
      

<p>2016年はVRとか流行りそうで、仮想空間での生活を妄想してしまう今日このごろ。
でも、今のままだとNPCがちゃんと自然に会話してくれない気がして微妙なんですよね。。。そこで、既存技術の延長で、どれくらいの日本語対話が可能か、ちょっと自分でも作ってみたくなりました。</p>

<p>自然言語処理をちゃんと勉強したことはないけれど、脳型情報処理アプローチでいくとしたら、結局はベクトル時系列データの処理なのかな？って思います。とりあえず、色々試してみましょう。</p>

<p>たぶん、進め方はこんな感じ。</p>

<ol>
<li>単語のベクトルデータ化（言語コーパス？）</li>
<li>対話データのベクトル時系列データ化（対話コーパス？）</li>
<li>会話時系列データにおける応答時系列データの予測学習</li>
<li>学習結果を用いた対話システム構築</li>
</ol>

<p>というわけで、今回は１の言語コーパス作成について。単語を入力とし、N次元ベクトルに変換することを目標。似たような単語は近くに配置されるような変換が好ましい（分散表現だ！）。</p>

<h1 id="言語コーパスをwikipediaの記事から作成:9f533d3f859ab3c9a17cb0f76df4e5f1">言語コーパスをWikipediaの記事から作成</h1>

<h2 id="wikipediaの日本語記事をダウンロード:9f533d3f859ab3c9a17cb0f76df4e5f1">wikipediaの日本語記事をダウンロード</h2>

<pre><code>$ curl -O http://dumps.wikimedia.org/jawiki/latest/jawiki-latest-pages-articles.xml.bz
</code></pre>

<h2 id="mecabをインストール:9f533d3f859ab3c9a17cb0f76df4e5f1">mecabをインストール</h2>

<p>単語の分かち書きへ変換するためのツールです。macならbrewでインストール可能。</p>

<pre><code>$ brew install mecab
$ brew install mecab-ipadic
</code></pre>

<h3 id="新語用辞書をインストール:9f533d3f859ab3c9a17cb0f76df4e5f1">新語用辞書をインストール</h3>

<p>最近の単語は、brewでインストールされた辞書には含まれていないので、新語に対応した辞書に更新します。</p>

<pre><code>$ git clone --depth 1 git@github.com:neologd/mecab-ipadic-neologd.git
$ cd mecab-ipadic-neologd/
$ ./bin/install-mecab-ipadic-neologd -n   # 辞書updateも同じコマンド
$ echo `mecab-config --dicdir`&quot;/mecab-ipadic-neologd&quot;  # 実行時指定のパスを調べる
/usr/local/lib/mecab/dic/mecab-ipadic-neologd
</code></pre>

<h3 id="参考-新御用辞書有無を確認:9f533d3f859ab3c9a17cb0f76df4e5f1">（参考）新御用辞書有無を確認</h3>

<pre><code>$ pip install mecab
$ python
In [1]: import MeCab
In [2]: mecab_org = MeCab.Tagger(&quot;-Owakati&quot;)
In [3]: mecab_new = MeCab.Tagger(&quot;-Owakati -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd&quot;)
In [4]: print mecab_org.parse(&quot;電力自由化がはじまる&quot;)
電力 自由 化 が はじまる
In [5]: print mecab_new.parse(&quot;電力自由化がはじまる&quot;)
電力自由化 が はじまる
</code></pre>

<p>なんとなく最近ニュースとかで出てくるような単語を分かち書き出来ている（気がします）。</p>

<h2 id="wikipediaを分かち書き:9f533d3f859ab3c9a17cb0f76df4e5f1">wikipediaを分かち書き</h2>

<p>各単語に分かち書き変換します。</p>

<h3 id="htmlタグとかを取っ払って文章だけに変換:9f533d3f859ab3c9a17cb0f76df4e5f1">HTMLタグとかを取っ払って文章だけに変換</h3>

<pre><code>$ echo 'gem &quot;wp2txt&quot;' &gt;&gt; Gemfile
$ bundle
$ bundle exec wp2txt --input-file jawiki-latest-pages-articles.xml.bz
$ ls wp2txt/  # 変換結果
$ rm jawiki-latest-pages-articles.xml.bz # 不要だから消す
$ cat wp2txt/jawiki-latest-pages-articles-* &gt; corpus.txt # 変換結果を一つのファイルに連結
</code></pre>

<p>とても時間かかります&hellip;
記号除去とかした方が良いのかどうか、今のところ謎です。</p>

<h3 id="新語辞書使って分かち書き:9f533d3f859ab3c9a17cb0f76df4e5f1">新語辞書使って分かち書き</h3>

<pre><code>$ mecab -Owakati -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd corpus.txt &gt; corpus_wakati.txt
</code></pre>

<p>とても時間かかります&hellip;</p>

<h2 id="word2vecによるベクトル化:9f533d3f859ab3c9a17cb0f76df4e5f1">word2vecによるベクトル化</h2>

<p>今後pythonで実装することもあり、gensim使います。</p>

<pre><code>$ pip install gensim
</code></pre>

<h3 id="utf-8に変換:9f533d3f859ab3c9a17cb0f76df4e5f1">utf-8に変換</h3>

<p>しないとword2vecのときに、文字コードについて怒られたので&hellip;</p>

<pre><code>$ iconv -c -t UTF-8 &lt; corpus_wakati.txt &gt; corpus_wakati_utf-8.txt
</code></pre>

<h3 id="学習:9f533d3f859ab3c9a17cb0f76df4e5f1">学習</h3>

<p>以下のpythonコードを実行します。次元は適当に中程度としました。</p>

<pre><code>$ vi word2vec_train.py
# coding: utf-8
from gensim.models import word2vec
import sys, logging, string, codecs

logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

# 学習（400次元だと４コアで約３時間...）
sentences = word2vec.Text8Corpus(&quot;corpus_wakati_utf-8.txt&quot;)
model = word2vec.Word2Vec(sentences, size=400, workers=4)
# モデルの保存
model.save(&quot;w2v_model_%d_dims&quot; % dims)
</code></pre>

<h3 id="検証:9f533d3f859ab3c9a17cb0f76df4e5f1">検証</h3>

<h4 id="モデルの読み込み:9f533d3f859ab3c9a17cb0f76df4e5f1">モデルの読み込み</h4>

<pre><code>$ pyton
In [1]: from gensim.models import word2vec
In [2]: model = word2vec.Word2Vec.load(&quot;./word2vec_models/w2v_model_%d_dims&quot; % 400)
</code></pre>

<h4 id="ベクトル空間上で近い単語を探す:9f533d3f859ab3c9a17cb0f76df4e5f1">ベクトル空間上で近い単語を探す</h4>

<p>動作確認です。</p>

<pre><code>In [3]: most_similar = model.most_similar(positive=[u'サッカー'])[0]
In [4]: most_similar[0]
ラグビー
In [5]: most_similar[1]
0.663492918015  # コサイン距離？
</code></pre>

<h4 id="ベクトル取得:9f533d3f859ab3c9a17cb0f76df4e5f1">ベクトル取得</h4>

<p>このベクトルに対して今後処理していくことになります。</p>

<pre><code>In [1]: vector = model[u'サッカー']
array([  2.69545317e-01,  -1.99663490e-01,   9.52050760e-02,
         2.16732353e-01,   1.97090670e-01,  -1.90409079e-01,
         ...
In [2]: vector.shape
(400,)
In [3]: vector.min()
-0.71880466
In [4]: vector.max()
0.75658286
</code></pre>

<h4 id="ベクトルから単語を探す:9f533d3f859ab3c9a17cb0f76df4e5f1">ベクトルから単語を探す</h4>

<p>処理結果のベクトルから単語を復元する手段も確認しておきます。</p>

<pre><code>In [5]: vector[0:10] = 0.0  # 適当に変更
In [6]: for cname in [candidate[0] for candidate in model.most_similar(positive=[vector], topn=3)]:
            print cname
サッカー
ラグビー
フットサル
</code></pre>

<h2 id="おわり:9f533d3f859ab3c9a17cb0f76df4e5f1">おわり</h2>

<p>ひとまず今回はここまで。単語をベクトル化したことにより、文章をベクトル時系列データとして扱うことが出来、色々な機械学習手法が適用可能になりました。
次回以降色々試してみたいと思います。</p>

<hr />

<h1 id="おまけ:9f533d3f859ab3c9a17cb0f76df4e5f1">おまけ</h1>

<p>この時点でも色々作って遊べますね。例えば、以前作った絵文字サジェスト用hubotでは、キーワードに近しい、絵文字キーワードを引っ張ってきて候補を表示してました。Githubとかだと、標準でも絵文字キーワードを入力すると、続きをサジェストしてくれるものの、そもそものキーワードが思いつかなかったりするので、そういうときに便利です :)</p>

<p><img src="http://blog.hassaku-labs.com/images/post/dialogue_system1/word2emoji.jpg" alt="word2emoji.jpg" /></p>

      
      
      <div id="share-this" class="col span_10">
        <span class='st_twitter_large' displayText='Tweet'></span>
        <span class='st_facebook_large' displayText='Facebook'></span>
        <span class='st_googleplus_large' displayText='Google +'></span>
        <span class='st_pocket_large' displayText='Pocket'></span>
        <span class='st_sharethis_large' displayText='ShareThis'></span>
        <span class='st_email_large' displayText='Email'></span>  
      </div>
    </article>
    
 <aside><div id="disqus_thread"></div></aside> 

<script type="text/javascript">
     
    var disqus_shortname = 'hassakusblog';

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

  </main>
  
  <nav class="pagination">
    
      <span class="previous">&larr; <a href="http://blog.hassaku-labs.com/post/exception_slacker/" rel="prev">exception-slackerというライブラリをPyPIに登録した</a></span>
    
    
      <span class="next"><a href="http://blog.hassaku-labs.com/post/pretrained-word2vec/" rel="next">学習済みword2vecモデルを調べてみた</a> &rarr;</span>
    
  </nav>


  
  <footer role="contentinfo">
    <div style="text-align:center;">
      <img src="http://blog.hassaku-labs.com/images/profile.png" width="64" height="64"><br>
      Written by hassaku
    </div>
  </footer>


</div>

<script src="http://blog.hassaku-labs.com/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-31136981-6', 'auto');
	ga('send', 'pageview');
</script>

</body>
</html>

