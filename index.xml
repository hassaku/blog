<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hassaku&#39;s blog</title>
    <link>http://blog.hassaku-labs.com/</link>
    <description>Recent content on hassaku&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 05 May 2019 10:00:00 +0900</lastBuildDate>
    <atom:link href="http://blog.hassaku-labs.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>機械学習技術を使った実際の研究開発プロジェクトについて</title>
      <link>http://blog.hassaku-labs.com/post/machine-learning-project/</link>
      <pubDate>Sun, 05 May 2019 10:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/machine-learning-project/</guid>
      <description>

&lt;p&gt;まずはざっくり箇条書き。多くを説明すべきところは、そのうち別の記事にするかも。&lt;/p&gt;

&lt;h1 id=&#34;全体的な雰囲気:d69212eb41b9ab5639c2ccaa05b1fd75&#34;&gt;全体的な雰囲気&lt;/h1&gt;

&lt;p&gt;機械学習技術が必要になる仕事は全体の２割程度。よって、機械学習技術に精通していなくても活躍できる場面は多い。
むしろ、AutoMLや機械学習部分を自動化するようなフレームワークやツールが増えてきており、その他８割の方が今後は重要になるとも言える。
もちろん、その他作業を効率良く進めるためには、詳しいメンバーがいるに越したことはない。&lt;/p&gt;

&lt;h1 id=&#34;だいたいの流れ:d69212eb41b9ab5639c2ccaa05b1fd75&#34;&gt;だいたいの流れ&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;解こうとしている課題の理解

&lt;ul&gt;
&lt;li&gt;本当に機械学習必要としているのかも早めに議論が必要&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;データの理解

&lt;ul&gt;
&lt;li&gt;可視化とか色々して仮説を立てる準備を整える&lt;/li&gt;
&lt;li&gt;この時点でゴミデータの存在には気づいておくことが大事&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;仮説の検討

&lt;ul&gt;
&lt;li&gt;人がちょっと考えて解ける問題は、入出力前提が同じであれば、（たぶん）機械学習で解ける&lt;/li&gt;
&lt;li&gt;例）加速度センサーのデータを見て、走っているか歩いているかを判定する&lt;/li&gt;
&lt;li&gt;データが十分にあればDeep Learningを試しても良いだろう&lt;/li&gt;
&lt;li&gt;データが少なかったり、なんとなくルールが見えているような場合は、適切な特徴量エンジニアリングと判別器で解けるだろう&lt;/li&gt;
&lt;li&gt;仮説検討時の思考過程を参考にすること&lt;/li&gt;
&lt;li&gt;人が考えてもなんだか分からない場合&lt;/li&gt;
&lt;li&gt;例）加速度センサーのデータを見て、病気かどうか判定する&lt;/li&gt;
&lt;li&gt;他のデータを使えるか相談したり、そもそも病気ではないものを判定するタスクに置き換えられないか検討するといいかも&lt;/li&gt;
&lt;li&gt;機械学習精度どうこうの前に、そもそも実現性の検証が必要となり、だいたいコスパ悪い

&lt;ul&gt;
&lt;li&gt;一方で実現できたときは、優位性が認められることになるので、挑戦することは否定しない（置かれている状況次第）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;データセットの準備

&lt;ul&gt;
&lt;li&gt;学習用、検証用、評価用&lt;/li&gt;
&lt;li&gt;検証用、評価用データの抽出には時間をかけて良い&lt;/li&gt;
&lt;li&gt;データ不足や偏り&lt;/li&gt;
&lt;li&gt;モデル選択・パラメータチューニング用に評価用データを使うことがないように十分注意すること

&lt;ul&gt;
&lt;li&gt;検証用で色々最適化した結果、評価用でも良い結果。というのが期待される進捗&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;解こうとしているタスクに対して適切かどうか、見極めがとても大事&lt;/li&gt;
&lt;li&gt;適当に進めて間違っていた場合、このあとのプロセスが全て台無しになるだろう

&lt;ul&gt;
&lt;li&gt;適当に選んでいわゆるleakageがあったりすると悲惨&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;評価尺度の定義

&lt;ul&gt;
&lt;li&gt;ビジネス課題との整合性確認&lt;/li&gt;
&lt;li&gt;単なるF値やAUCを追い求めたら良いのか？あるいは、Precisionを重視してほしいのか等&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;評価系の構築

&lt;ul&gt;
&lt;li&gt;適切なデータセットと評価尺度が用意できれば、ほぼ終わったも同然（？）&lt;/li&gt;
&lt;li&gt;このあとはここまで色々頑張ってきた準備に対する、収穫の時期となるだろう&lt;/li&gt;
&lt;li&gt;変な話、機械学習技術について精通した人が、機械学習未満のここまでをちゃんと設計出来ていると良いかも&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;特徴抽出の検討

&lt;ul&gt;
&lt;li&gt;あとで色々組み合わせたり、除外したくなるので、特徴量毎に個別CSV化しておくなどしておくと良い&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;機械学習技術の検討

&lt;ul&gt;
&lt;li&gt;ルールベースやロジスティック回帰などシンプルな手法で早めにベースラインを用意&lt;/li&gt;
&lt;li&gt;楽しい ٩( &amp;lsquo;ω&amp;rsquo; )و ♬*&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;検討した手法の評価

&lt;ul&gt;
&lt;li&gt;並列化とか早めにして、試行錯誤をすばやくする仕組みが大事&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;評価結果の課題分析

&lt;ul&gt;
&lt;li&gt;underfitting&lt;/li&gt;
&lt;li&gt;表現能力を上げる。Deep Learningだったら層や素子数、その他だったら特徴量増やしたり&lt;/li&gt;
&lt;li&gt;overfitting&lt;/li&gt;
&lt;li&gt;正則化とかデータ増やしたりとか&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;システム統合

&lt;ul&gt;
&lt;li&gt;精度を犠牲にしてでも、処理速度を上げたりしないといけないかも&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;統合後の逐次評価

&lt;ul&gt;
&lt;li&gt;未知データの出現や分布、特徴の傾向が変化するかもしれないので継続的な改善は必要&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;各プロセスで、なにか壁にぶつかったら、必要なところまで戻り、を繰り返すのが機械学習リサーチエンジニアの主な仕事（たぶん）。&lt;/p&gt;

&lt;h1 id=&#34;進捗が芳しくない状況でありそうなケース:d69212eb41b9ab5639c2ccaa05b1fd75&#34;&gt;進捗が芳しくない状況でありそうなケース&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;パラメータチューニングばかりやってる&lt;/li&gt;
&lt;li&gt;データクレンジングしてない&lt;/li&gt;
&lt;li&gt;課題を適切に分割してない&lt;/li&gt;
&lt;li&gt;解こうとしている問題のコスパが悪い&lt;/li&gt;
&lt;li&gt;仮説もってない&lt;/li&gt;
&lt;li&gt;トレードオフを行ったり来たりしてる&lt;/li&gt;
&lt;li&gt;etc&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;一時的なサポートメンバーに仕事を任せるために考えること:d69212eb41b9ab5639c2ccaa05b1fd75&#34;&gt;一時的なサポートメンバーに仕事を任せるために考えること&lt;/h1&gt;

&lt;p&gt;いま一番頭を悩ましている部分&amp;hellip;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;評価系まではきちんと作り込んでおく&lt;/li&gt;
&lt;li&gt;自走出来なそうなら、試行錯誤するための手順をある程度つけておく

&lt;ul&gt;
&lt;li&gt;任せられるタスク範囲が絞られるのでトレードオフ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;手順化したようなところは自動化出来てしまったりするので悩ましかったりもする&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;進捗ミーティングとかで共有すべき内容:d69212eb41b9ab5639c2ccaa05b1fd75&#34;&gt;進捗ミーティングとかで共有すべき内容&lt;/h1&gt;

&lt;p&gt;やったことではなく、出来たことの説明を優先すべき&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;今回解決しようとした課題&lt;/li&gt;
&lt;li&gt;今回の課題が全体に占める割合&lt;/li&gt;
&lt;li&gt;解決方法&lt;/li&gt;
&lt;li&gt;結果

&lt;ul&gt;
&lt;li&gt;検討開始からの評価結果推移&lt;/li&gt;
&lt;li&gt;課題解決を確認できそうな代表的なグラフ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;残課題&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;場合によっては活きてくるアドバンスドな-手法:d69212eb41b9ab5639c2ccaa05b1fd75&#34;&gt;場合によっては活きてくるアドバンスドな(?)手法&lt;/h1&gt;

&lt;p&gt;まずはトイタスクを用意して、原理検証することが大事&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;特権付き機械学習&lt;/li&gt;
&lt;li&gt;ロバスト最適化&lt;/li&gt;
&lt;li&gt;Semi-superised学習&lt;/li&gt;
&lt;li&gt;Positive-unlabeled学習&lt;/li&gt;
&lt;li&gt;共変量シフト適応&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;一般的なシステム開発プロジェクトと比べたときの難しさ:d69212eb41b9ab5639c2ccaa05b1fd75&#34;&gt;一般的なシステム開発プロジェクトと比べたときの難しさ&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/@l2k/why-are-machine-learning-projects-so-hard-to-manage-8e9b9cf49641&#34;&gt;https://medium.com/@l2k/why-are-machine-learning-projects-so-hard-to-manage-8e9b9cf49641&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;事前に難易度の見通しが付きづらい

&lt;ul&gt;
&lt;li&gt;その課題で90%の意味するところは？そもそも実現可能？70%でも十分では？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;想定外に失敗することがある

&lt;ul&gt;
&lt;li&gt;突如としてデータの傾向が変わるなど（金融データとか）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;十分なデータが必要

&lt;ul&gt;
&lt;li&gt;多ければ良いというわけではなく、適切なデータを集めなくてはならない&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>データ分析コンペとかによくやる作業</title>
      <link>http://blog.hassaku-labs.com/post/data-comp-memo/</link>
      <pubDate>Fri, 03 May 2019 10:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/data-comp-memo/</guid>
      <description>

&lt;h1 id=&#34;大きいデータの読み込み:61f9dc3dc817dd778c88b7321db80ab0&#34;&gt;大きいデータの読み込み&lt;/h1&gt;

&lt;p&gt;daskを使って並列処理&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import dask.dataframe as ddf
import dask.multiprocessing

df = ddf.read_csv(&#39;train_data.csv&#39;)
df = df.compute(get=dask.multiprocessing.get)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;eda:61f9dc3dc817dd778c88b7321db80ab0&#34;&gt;EDA&lt;/h1&gt;

&lt;p&gt;データに関する簡単な統計情報確認&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import pandas_profiling as pdp
pdp.ProfileReport(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;データの相関を確認&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import seaborn as sns
sns.pairplot(df, hue=&amp;quot;target&amp;quot;, diag_kind=&amp;quot;kde&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;前処理:61f9dc3dc817dd778c88b7321db80ab0&#34;&gt;前処理&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;欠損値の補完&lt;/li&gt;
&lt;li&gt;外れ値の削除&lt;/li&gt;
&lt;li&gt;カテゴリ変数の扱い

&lt;ul&gt;
&lt;li&gt;one hot encoding （次元増える系）&lt;/li&gt;
&lt;li&gt;どれかひとつだけ1になるようなスパースなベクトル表現&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  city_dummies = pd.get_dummies(df[&amp;quot;city&amp;quot;], prefix=&amp;quot;city&amp;quot;)
  df.drop([&amp;quot;city&amp;quot;], axis=1, inplca=True)
  df = df.join(city_dummies)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;count encoding （次元増えない系）

&lt;ul&gt;
&lt;li&gt;カテゴリ変数の出現回数（あるいは率）を値とするような表現&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  df[&#39;count_city&#39;] = df.groupby(&#39;city&#39;)[&#39;target&#39;].transform(&#39;count&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;並列処理&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  import numpy as np
  import pandas as pd
  #import multiprocessing as mp  # impossible to use lambda with pickle
  import pathos.multiprocessing as mp  # dill is used inside instead of pickle.

  def split_parallel(df, num_split, map_func):
      with mp.Pool(num_split) as p:
          df_split = np.array_split(df, num_split*2)
          result = p.map(map_func, df_split)
      return pd.concat(result)

  NUM_PARALLELS = 3
  df[&amp;quot;new_col&amp;quot;] = split_parallel(df, NUM_PARALLELS, lambda x: x[&amp;quot;col1&amp;quot;] + x[&amp;quot;col2&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;cv:61f9dc3dc817dd778c88b7321db80ab0&#34;&gt;CV&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;from sklearn.model_selection import StratifiedKFold

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)
X_train = np.zeros(20, 5)
y_train = np.zeros(20)

for train_idx, valid_idx in cv.split(X_train, y_train):
    print(train_idx, valid_idx)
    ...
    losses.append(loss)

cv_loss = np.mean(losses)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;結果のアンサンブル:61f9dc3dc817dd778c88b7321db80ab0&#34;&gt;結果のアンサンブル&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;res1 = pd.read_csv(&#39;../method1/submission.csv&#39;)
res2 = pd.read_csv(&#39;../method2/submission.csv&#39;)
res3 = pd.read_csv(&#39;../method3/submission.csv&#39;)

b1 = res1.copy()
col = res1.columns

col = col.tolist()
col.remove(&#39;id&#39;)
for i in col:
    b1[i] = (2 * res1[i]  + 2 * res2[i] + 4 * res3[i]) / 6.0

b1.to_csv(&#39;submission.csv&#39;, index=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;jupyter-notebook上でcsvの確認とダウンロード:61f9dc3dc817dd778c88b7321db80ab0&#34;&gt;Jupyter Notebook上でCSVの確認とダウンロード&lt;/h1&gt;

&lt;p&gt;実行するとディレクトリ内のファイル一覧が表示されて、クリックすればダウンロード出来るはず&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from IPython.display import FileLinks
FileLinks(DATA_DIR)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>人工知能実現のための要素技術アイデア</title>
      <link>http://blog.hassaku-labs.com/post/ai-ideas/</link>
      <pubDate>Thu, 02 May 2019 10:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/ai-ideas/</guid>
      <description>

&lt;p&gt;ただの夢想です。実現するには時間も考えも足りないので、忘れないうちに言語化しておきます。&lt;/p&gt;

&lt;h1 id=&#34;実現したいこと:781c8ffbbe578c698fac6a5653ee4ea2&#34;&gt;実現したいこと&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;コンセプト

&lt;ul&gt;
&lt;li&gt;心を感じるような人工的な知能を実現すること&lt;/li&gt;
&lt;li&gt;条件反射ではない、なにか考えているような印象を与えてくれる&lt;/li&gt;
&lt;li&gt;常に学習し続けていて、変化を伴う&lt;/li&gt;
&lt;li&gt;「疲れている」と伝えれば、それに共感してくれたり、自身のことを話してくれたりするイメージ&lt;/li&gt;
&lt;li&gt;知りたいことが返ってこなくても良い。むしろ何か見えないダイナミクスを感じさせてくれる挙動が大事&lt;/li&gt;
&lt;li&gt;知識の抽出だけではなく、知識の使い方をも自律的に発見する&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;シミュレーション

&lt;ul&gt;
&lt;li&gt;ユーザ（私）と体験をある程度共有出来るような環境&lt;/li&gt;
&lt;li&gt;グリッドワールドでも良い。その中に、時間や環境（温度や明るさ）、空腹感などの外的変動要素が含まれていること&lt;/li&gt;
&lt;li&gt;「今日は暑いね」と言えば、「暑いとは温度が比較的高いこと」など体験に基づいて内的に理解出来ていること&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;要素技術:781c8ffbbe578c698fac6a5653ee4ea2&#34;&gt;要素技術&lt;/h1&gt;

&lt;p&gt;情報表現も記憶も全ては動的であり、それを制御するための力学系を有すること&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;機構&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;基本は深層ニューラルネットのように徐々に抽象化されていく仕組み&lt;/li&gt;
&lt;li&gt;ただし層数は事前に決まらず、ニューロン同士の結合有無組み合わせ、再帰的な回路、時間発展によって、機能的に深層構造と同等の機能が動的に実現される&lt;/li&gt;
&lt;li&gt;結合の仕方を他のニューラルネットの状態によって制御出来れば、状況によって最適な構造（表現能力）を動的に用いることが出来る&lt;/li&gt;
&lt;li&gt;ある２つの情報が、同じカテゴリとして表現したいときもあれば、明確に区別したいときもあり、Attention機構（回路構造の指定）によって動的に制御される&lt;/li&gt;
&lt;li&gt;結合有無に関しては、MC Dropoutのようにある種のランダムを持たせて、いくらか学習が進んだあとに、エントロピー的計算により既知未知をある程度算出できる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;学習方法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;常に学習し続けても破綻しない&lt;/li&gt;
&lt;li&gt;誤差逆伝搬だと追加学習や並列学習に難があるので、Equilibrium Propagationのようなローカルな方法が望ましい&lt;/li&gt;
&lt;li&gt;誤差を求めるための正解値みたいなものは基本的に明示されず、自身の行動を決める上で、その情報表現が適切か不適切かを指標とする&lt;/li&gt;
&lt;li&gt;言い換えると、全ては時系列の予測学習であり、予測が出来るように学習していくことが基本的な戦略&lt;/li&gt;
&lt;li&gt;時系列の先が同じであれば、表現は近くなるといった、CBOWとかskip-gramのイメージにも近い&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;記憶&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;大脳皮質の役割で、まだあまり議論されていないように思える&lt;/li&gt;
&lt;li&gt;hopfield型NNのようにアトラクタを有する力学系で実現される&lt;/li&gt;
&lt;li&gt;追加学習をしても過去の記憶は壊れない。ただし、想起しづらくなることはある&lt;/li&gt;
&lt;li&gt;AからBの予測を単に関数近似ではなく、神経力学系上の時間発展が可能とする連想記憶によって実現される&lt;/li&gt;
&lt;li&gt;これによりA-&amp;gt;B、B-&amp;gt;Cを個別に学習しておくだけで、A-&amp;gt;Cの三段論法的な表現も自動的に獲得される&lt;/li&gt;
&lt;li&gt;様々な角度の連想記憶は、力学系の部分空間の切り替えによって動的に制御される&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;探索&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;根底にあるのは欲求や感覚であり、持って生まれるものとする&lt;/li&gt;
&lt;li&gt;明示的なゴールは基本的に与えられない&lt;/li&gt;
&lt;li&gt;ご飯は食べれば食欲は満たされるポジティブな情報として、嫌なことは最終的に痛みに結びつきネガティブな情報として表現できる&lt;/li&gt;
&lt;li&gt;また、既知未知を表現できることで、知識欲を満たすように自律的な探索行動もできる&lt;/li&gt;
&lt;li&gt;そうやって、ネガティブなことを避けつつ、ポジティブなことを追い求めていく中で、徐々に外界情報が内部表現として整理されていく&lt;/li&gt;
&lt;li&gt;そうした中で、ユーザ（私）との共通認識みたいなものも生まれて、コミュニケーションも取れるようになるはず&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;書きかけであり、適宜追記するし、画像も用意する&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GASで作る日常ツールあれこれ</title>
      <link>http://blog.hassaku-labs.com/post/gas/</link>
      <pubDate>Wed, 01 May 2019 10:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/gas/</guid>
      <description>

&lt;h1 id=&#34;基本-google-apps-scriptの作り方:ade2431a67148677c334b673f0d1d121&#34;&gt;【基本】Google Apps Scriptの作り方&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;スプレッドシート作成&lt;/li&gt;
&lt;li&gt;ツール - スクリプトエディタ&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;基本-webapi化の共通事項:ade2431a67148677c334b673f0d1d121&#34;&gt;【基本】WebAPI化の共通事項&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;doPostという関数&lt;/li&gt;
&lt;li&gt;公開 &amp;gt; webアプリケーションとして導入 を選び公開&lt;/li&gt;
&lt;li&gt;コードを修正した場合、バージョン に 新規作成 を選択する必要がある。&lt;/li&gt;
&lt;li&gt;アクセス出来るユーザは全員（匿名）にしておくこと&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;基本-簡単なデータストア先として活用:ade2431a67148677c334b673f0d1d121&#34;&gt;【基本】簡単なデータストア先として活用&lt;/h1&gt;

&lt;p&gt;WiFi接続のセンサモジュールとか、ちょっとしたものからデータを記録していきたいときに利用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var sheet = SpreadsheetApp.openById(URLのところに表示されるID).getSheetByName(シート名);

function doPost(e) {
  var array = [e.parameter.timestamp, e.parameter.sensor_id, e.parameter.value];
  sheet.appendRow(array);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ curl -X POST -F &amp;quot;timestamp=`date &amp;quot;+%Y%m%d %H:%M:%S&amp;quot;`&amp;quot; -F &#39;sensor_id=1234&#39; -F &#39;value=5678&#39; 公開時に表示されるURL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;スプレッドシートにデータが追記されていくので、それをCSV化してデータ分析するなり、簡単に可視化するなり。&lt;/p&gt;

&lt;h1 id=&#34;基本-slack通知の共通部分:ade2431a67148677c334b673f0d1d121&#34;&gt;【基本】Slack通知の共通部分&lt;/h1&gt;

&lt;p&gt;以下の各事例でも頻繁に使われてる&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
リソース - ライブラリから以下を追加
- SlackApp: M3W5Ut3Q39AaIwLquryEPMwV62A3znfOO
- Underscore: MGwgKN2Th03tJ5OdmlzB8KPxhMjh3Sh48
- Moment: MHMchiX6c1bwSqGM1PZiW_PxhMjh3Sh48
*/

var _ = Underscore.load();
var TOKEN = &amp;quot;SLACK_TOKEN&amp;quot;;

var slackApp = SlackApp.create(TOKEN);

function getChannelId(name) {
  // チャンネル名から通知に必要なIDを取得
  var channel = _.findWhere(slackApp.channelsList().channels, {name: name});
  if (_.isEmpty(channel)) {
    throw new Error(name + &amp;quot; is not found&amp;quot;);
  }
  return channel.id
}

function postMessage(channel_name, message) {
  // 任意のメッセージを通知
  var channelId = getChannelId(slackApp, channel_name);

  slackApp.chatPostMessage(channelId, message, {
    username : &amp;quot;bot&amp;quot;,
    icon_emoji : &amp;quot;:mega:&amp;quot;
  });
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;googleドキュメント-スライド定期複製:ade2431a67148677c334b673f0d1d121&#34;&gt;Googleドキュメント・スライド定期複製&lt;/h1&gt;

&lt;p&gt;定例ミーティングなどで、毎回人手で過去分議事録をコピーして、事前メモ用ドキュメントを作成しているケースがあったので自動化した。
コピー元は、前回分とかではなく、毎回決まったテンプレートとかを指定しても良い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function createCopy(fileId, fileName) {
  // 最新の日付を付けたコピーを作成
  var date = new Date();
  date.setDate(date.getDate());
  var formattedDate = Utilities.formatDate(date, &amp;quot;JST&amp;quot;, &amp;quot;yyyyMMdd&amp;quot;);
  var f = DriveApp.getFileById(fileId);

  f = f.makeCopy(formattedDate + &amp;quot;_&amp;quot; + fileName);
  return f.getUrl();
}

function latestFileId(folderId, fileName) {
  // 前回分のファイルを取得
  var folder = DriveApp.getFolderById(folderId);
  var contents = folder.getFiles();

  var latest = 0;
  var latestFileId = 0;

  while(contents.hasNext()) {
    var file = contents.next();
    var name = file.getName();

    if (!name.match(new RegExp(&amp;quot;^.*_&amp;quot; + fileName +&amp;quot;$&amp;quot;))) {
      continue;
    }

    // 20190501_XXXXX みたいな名称を想定
    var updatedAt = parseInt(name.slice(0, 10), 10);
    var fileId = file.getId()

    if(latest &amp;lt; updatedAt) {
      latest = updatedAt;
      latestFileId = fileId;
    }
  }
  return latestFileId;
};

function main() {
  var channel_name = &amp;quot;通知したいSlackチャンネル名&amp;quot;;
  var fileName = &amp;quot;XXXXX&amp;quot;;
  var folderId = &amp;quot;Google Driveで対象ファイルが配置されているフォルダのURLに含まれるID&amp;quot;;

  var fileId = latestFileId(folderId, fileName);
  var url = createCopy(fileId, fileName);
  postMessage(channel_name, &amp;quot;XXXXXのアジェンダを作成しました。 -&amp;gt; &amp;quot; + url);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;編集 - 現在のプロジェクトのトリガーからmain指定すれば、定期実行させることが出来る&lt;/p&gt;

&lt;h1 id=&#34;ドライブ更新通知:ade2431a67148677c334b673f0d1d121&#34;&gt;ドライブ更新通知&lt;/h1&gt;

&lt;p&gt;ドライブにファイルが追加されたりしたときにSlack通知&lt;/p&gt;

&lt;p&gt;予めconfigというシートにfolder_id, slack_channel, messageの列を作っておき、
- floder_id
  - Google Driveの対象フォルダのURLに含まれるID
- slack_channel
  - 通知したいSlackチャンネル名
- message
  - 通知時のメッセージ
を定義しておくこと。複数可。&lt;/p&gt;

&lt;p&gt;また、トリガは１分ごと実行に設定。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var INTERVAL_MINUTES = 1;  // １分以内に更新されたやつを対象とする

function checkFolder(folderId, channelName, message) {
  var folder = DriveApp.getFolderById(folderId);
  var now = Moment.moment();
  var updates = [];

  var files = folder.getFiles();
  while (files.hasNext()) {
    var file = files.next();
    var updatedAt = Moment.moment(file.getLastUpdated());
    var elapsedMinutes = (now - updatedAt) / 1000 / 60

    if (elapsedMinutes &amp;lt; INTERVAL_MINUTES) {
      updates.push(file.getName());
    }
  }

  var folders = folder.getFolders();
  while (folders.hasNext()) {
    var folder = folders.next();
    var updatedAt = Moment.moment(folder.getLastUpdated());
    var elapsedMinutes = (now - updatedAt) / 1000 / 60

    if (elapsedMinutes &amp;lt; INTERVAL_MINUTES) {
      updates.push(folder.getName());
    }
  }

  if (_.isEmpty(updates)) {
    return;
  }

  message = updates.join(&#39;, &#39;) + &amp;quot; was updated at https://drive.google.com/drive/u/0/folders/&amp;quot; + folderId + &#39;\n&#39; + message
  postMessage(message, channelName)
}

function main() {
  var sheet = SpreadsheetApp.getActive().getSheetByName(&#39;config&#39;);
  var rows = sheet.getDataRange().getValues();

  _.each(rows, function(row, i){
    if (i==0) return;  // skip header
    var folderId = row[0];
    var channelName = row[1];
    var message = row[2];
    checkFolder(folderId, channelName, message);
  });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;slack新規チャンネル通知:ade2431a67148677c334b673f0d1d121&#34;&gt;Slack新規チャンネル通知&lt;/h1&gt;

&lt;p&gt;チャンネルが乱立し始めた頃、新しくチャンネルが出来たら通知して欲しいとの要望から作成した。
予めconfigという空シートを作成しておくこと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var CHANNEL_NAME = &amp;quot;lobby&amp;quot;;
var SHEET_NAME = &amp;quot;config&amp;quot;;
var ADDITIONAL_MESSAGE = &amp;quot;新しく作成されたチャンネルがあります。 &amp;quot;

function main() {
  var slackApp = SlackApp.create(TOKEN);
  var currentChannels = _.pluck(slackApp.channelsList().channels, &#39;name&#39;);
  var newChannels = [];

  var message = &#39;&#39;;
  var sheet = SpreadsheetApp.getActive().getSheetByName(SHEET_NAME);
  var rows = _.map(sheet.getDataRange().getValues(), function(elm){ return elm.toString(); });

  _.each(currentChannels, function(channel, i) {
    if (!_.include(rows, channel)) {
      message += &amp;quot; #&amp;quot; + channel;
      newChannels.push(channel);
    }
  });

  _.each(newChannels, function(channel, i) {
    sheet.getRange(&#39;A&#39; + (currentChannels.length - newChannels.length + i + 1)).setValue(channel);
  });

  if (message) postMessage(slackApp, ADDITIONAL_MESSAGE + message);

  _.each(currentChannels, function(channel, i) {
    sheet.getRange(&#39;A&#39; + (i+1)).setValue(channel);
  });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;環境センサ通知ボット:ade2431a67148677c334b673f0d1d121&#34;&gt;環境センサ通知ボット&lt;/h1&gt;

&lt;p&gt;オフィスに人が増えてきて、場所によっては酸素が薄いみたいな話がチラホラ聞こえてきた。
なので、そのへんに転がってた（？）Netatmoをばら撒いて、二酸化炭素濃度が上がってきたら通知するようにした。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var CHANNEL_NAME = &amp;quot;lobby&amp;quot;;
var THRESHOLD = 2000; // 通知しきい値
var STATION_NAME = &amp;quot;entrance&amp;quot;;  // Netatmoにつけた名称

function getToken() {
  var url = &#39;https://api.netatmo.net/oauth2/token&#39;;
  var options = {
    &#39;method&#39;: &#39;post&#39;,
    &#39;payload&#39;: {
      &#39;grant_type&#39;: &#39;password&#39;,  // パスワードフローでOAuthトークンを取得
      &#39;username&#39;: &#39;hoge@fuga.com&#39;,
      &#39;password&#39; : &#39;XXXXXXX&#39;,
      &#39;client_id&#39;: &#39;XXXXXXX&#39;,  // このへんの情報はNetatmoの設定ページから取得できる
      &#39;client_secret&#39;: &#39;XXXXXXX&#39;
     }
  };
  var json = UrlFetchApp.fetch(url, options).getContentText();
  var jsonData = JSON.parse(json);
  var token = jsonData[&amp;quot;access_token&amp;quot;];
  return token;
}

function getCo2() {
  var url = &amp;quot;https://api.netatmo.com/api/getstationsdata&amp;quot;;
  var options = {
    &amp;quot;headers&amp;quot; : {
      &amp;quot;Authorization&amp;quot; : &amp;quot;Bearer &amp;quot; + getToken()
    }
  };
  var json = UrlFetchApp.fetch(url, options);
  var jsonData = JSON.parse(json);
  var co2 = undefined
  jsonData[&amp;quot;body&amp;quot;][&amp;quot;devices&amp;quot;].some(function(device, i) {
    if(device[&amp;quot;station_name&amp;quot;] === STATION_NAME) {
      co2 = parseInt(device[&amp;quot;dashboard_data&amp;quot;][&amp;quot;CO2&amp;quot;], 10); // Netatmoは二酸化炭素以外にも気温、湿度とか色々取れるはず
    }
  });
  if(!co2) {
    throw new Error(&amp;quot;CO2が取得できませんでした&amp;quot;);
  }
  return co2;
}

function main() {
  var co2 = getCo2();
  if(co2 &amp;gt; THRESHOLD) {
    postMessage(CHANNEL_NAME, &amp;quot;オフィスの二酸化炭素濃度:&amp;quot; + co2 + &amp;quot;が閾値:&amp;quot; + THRESHOLD + &amp;quot;を上回りました。換気をするか、呼吸を控えてください。&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;slack簡易対話ボット:ade2431a67148677c334b673f0d1d121&#34;&gt;Slack簡易対話ボット&lt;/h1&gt;

&lt;p&gt;自分用のチャンネルがあって、そこに訪問する人に対して、簡易的に応答するボットを用意している。&lt;/p&gt;

&lt;p&gt;予め「responses」というシートに「発話内容」と「応答内容」の２列で色々と定義しておくこと。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var MAIN_CHANNEL_NAME = &amp;quot;my_room&amp;quot;;
var SUB_CHANNEL_NAME = &amp;quot;bot_room&amp;quot;;

function convertTime(unixtime) {
  var date = Moment.moment(new Date(unixtime*1000));
  return date.format(&amp;quot;YYYY-MM-DD_HH:mm:ss&amp;quot;);
}

function doPost(e) {
  if(e.parameter.userName === &amp;quot;slackbot&amp;quot;) {
    return null; // 無限ループ防止
  }

  if (prop.verifyToken != e.parameter.token) {
    throw new Error(&amp;quot;invalid token.&amp;quot;);
  }

  if(e.parameter.channel_name === MAIN_CHANNEL_NAME) {
    var userName = e.parameter.user_name;
    sheet = SpreadsheetApp.getActive().getSheetByName(userName);

    if(!sheet) {
      sheet = SpreadsheetApp.getActive().insertSheet(userName);

      // 初めて投稿してくれた人へのメッセージ
      slackApp.chatPostMessage(e.parameter.channel_id, &amp;quot;ようこそ。&amp;quot; + e.parameter.user_name + &amp;quot;さん&amp;quot;, {
        username : &amp;quot;bot&amp;quot;,
        icon_emoji : &amp;quot;:penguin:&amp;quot;
      });
    }

    // 投稿内容に応じたレスポンスを返す
    response = findResponse(e.parameter.text);
    if(response) {
      slackApp.chatPostMessage(e.parameter.channel_id, response, {
        username : &amp;quot;bot&amp;quot;,
        icon_emoji : &amp;quot;:penguin:&amp;quot;
      });
    } else {
      // 特にレスポンス内容が見つからなければ、SUB_CHANNEL_NAMEに投稿するだけ
      postMessage(SUB_CHANNEL_NAME, e.parameter.text);
    }

    // 後々の応答例用意のためにも、訪問者の投稿は保存（問題なさそうなチャンネルかどうかは要注意）。
    //sheet.appendRow([convertTime(e.parameter.timestamp), e.parameter.text, response]);

  } else {
    // SUB_CHANNEL_NAMEに投稿した内容をMAIN_CHANNEL_NAMEに投稿。元の投稿者からはあたかもbotが応答したように見える（かも）
    postMessage(MAIN_CHANNEL_NAME, e.parameter.text);
  }

  return null;
}

function findResponse(utterance) {
  // &amp;quot;responses&amp;quot;シートに定義された対話例の中から、発言を含むものを探し、あれば応答する。なければundefinedで応答しない。
  var response = getResponses().reduce(function(cache, row) { return cache || ((utterance.indexOf(row.utterance) != -1) &amp;amp;&amp;amp; row.response); }, false) || undefined;
  return response;
}

function getResponses() {
  var sheet = SpreadsheetApp.getActive().getSheetByName(&amp;quot;responses&amp;quot;);
  var data = sheet.getDataRange().getValues();
  return data.map(function(row) { return {utterance: row[0], response: row[1]}; }); // １列目が発話内容、２列目が応答内容
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;googleカレンダー予定簡易確認ボット:ade2431a67148677c334b673f0d1d121&#34;&gt;Googleカレンダー予定簡易確認ボット&lt;/h1&gt;

&lt;p&gt;協力会社の方など、社員用カレンダーを見れないが、（カレンダーで管理されている）会議室の予約をしたいという要望があった。
そのため、Slack上のスラッシュコマンドで空きの確認及び予約の作成を出来るようにした。&lt;/p&gt;

&lt;p&gt;使い方&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. 予約済み時間の確認
/room small list 2019/03/17

2. 予約の登録
/room small create 2019/03/17 09:00 09:30 Aさんと1on1

小会議室：small
大会議室：large
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://api.slack.com/apps&#34;&gt;https://api.slack.com/apps&lt;/a&gt;  にて、Create New Appすることにより、スラッシュコマンドで呼び出すBotを作る。
Botから呼び出し、カレンダーの管理をするGASは以下のとおり。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function doPost(e) {
  if (prop.verifyToken != e.parameter.token) {
    throw new Error(&amp;quot;invalid token.&amp;quot;);
  }

  var commands = e.parameter.text.split(&amp;quot; &amp;quot;);
  var roomType = commands[0];
  var command = commands[1];
  var targetDate = commands[2];

  if(roomType == &amp;quot;large&amp;quot;) {
    var cal = CalendarApp.getCalendarById(&amp;quot;大会議室のカレンダーID (Googleカレンダーの詳細ページに記載されているはず)&amp;quot;);
  } else if(roomType == &amp;quot;small&amp;quot;) {
    var cal = CalendarApp.getCalendarById(&amp;quot;小会議室のカレンダーID&amp;quot;);
  }

  if(command == &amp;quot;list&amp;quot;) {
    // 予約の確認
    var text = &#39;[予約済み]\n&#39;;
    var date = new Date(targetDate);　
    var events = cal.getEventsForDay(date);
    for each (var event in events) {
      var start = event.getStartTime();
      var end = event.getEndTime();
      text += &amp;quot;開始時刻: &amp;quot; + start.getHours() + &amp;quot;:&amp;quot; + start.getMinutes() + &amp;quot; 終了時刻: &amp;quot; + end.getHours() + &amp;quot;:&amp;quot; + end.getMinutes() + &#39;\n&#39;;
    }
  } else if (command == &amp;quot;create&amp;quot;) {
    // 予約の作成
    var text = &#39;予約を作成しました&#39;;
    var targetStart = commands[3];
    var targetEnd = commands[4];
    var eventName = commands[5];
    var start = new Date(targetDate + &amp;quot; &amp;quot; + targetStart);　
    var end = new Date(targetDate + &amp;quot; &amp;quot; + targetEnd);　
    cal.createEvent(eventName, start, end, {description: &#39;Created By Bot&#39;});
  }

  var res = {response_type: &amp;quot;in_channel&amp;quot;, text: text};
  return ContentService.createTextOutput(JSON.stringify(res)).setMimeType(ContentService.MimeType.JSON);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;チャンネル常時翻訳:ade2431a67148677c334b673f0d1d121&#34;&gt;チャンネル常時翻訳&lt;/h1&gt;

&lt;p&gt;英語常用の社員も増えてきたし、言語由来の壁が出来ないように、雑談用のチャンネルは常時機械翻訳するようにした。
翻訳精度はまだ怪しいが、雰囲気の共有くらいは出来る（はず）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var JA_CHANNEL_NAME = &amp;quot;lobby_ja&amp;quot;;
var TRANS_JA_CHANNEL_NAME = &amp;quot;lobby_ja_trans&amp;quot;;

var EN_CHANNEL_NAME = &amp;quot;lobby_en&amp;quot;;
var TRANS_EN_CHANNEL_NAME = &amp;quot;lobby_en_trans&amp;quot;;

function doPost(e) {
  if(e.parameter.user_name === &amp;quot;slackbot&amp;quot;) {
    return null; // 無限ループ防止
  }

  if(e.parameter.channel_name === JA_CHANNEL_NAME) {
    var translation = LanguageApp.translate(e.parameter.text, &#39;ja&#39;, &#39;en&#39;);
    postMessage(TRANS_JA_CHANNEL_NAME, e.parameter.user_name, translation);

  } else if(e.parameter.channel_name === EN_CHANNEL_NAME) {
    var translation = LanguageApp.translate(e.parameter.text, &#39;en&#39;, &#39;ja&#39;);
    postMessage(TRANS_EN_CHANNEL_NAME, e.parameter.user_name, translation);
  }

  return null;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;okになった行を隠す:ade2431a67148677c334b673f0d1d121&#34;&gt;OKになった行を隠す&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;function main(){
  var sheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName(&amp;quot;対象のシート名&amp;quot;);
  var maxRows = sheet.getMaxRows();

  sheet.showRows(1, maxRows);
  var data = sheet.getRange(&#39;AF:AF&#39;).getValues();  // AF列にOKと記入されている想定

  for(var i=0; i&amp;lt; data.length; i++){
    if(data[i][0] == &#39;OK&#39;){
      sheet.hideRows(i+1);  // 行を隠す
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>IDE使えないときの例外時デバッグ</title>
      <link>http://blog.hassaku-labs.com/post/debug-on-remote/</link>
      <pubDate>Mon, 25 Feb 2019 10:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/debug-on-remote/</guid>
      <description>&lt;p&gt;IDEが使える状況であれば、簡単にデバッガーを使えると思うが、そうでない環境でデバッグしたくなることもある。
printデバッグも辛いので、以下のような感じで例外時等にpython debuggerを起動出来ると便利。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sys

def hook(type, value, tb):
   if hasattr(sys, &#39;ps1&#39;) or not sys.stderr.isatty():
      sys.__excepthook__(type, value, tb)
   else:
      import traceback, pdb
      traceback.print_exception(type, value, tb)
      print()
      pdb.pm()

sys.excepthook = hook
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;というのを適当なところにdebug.pyとして置いておいて、デバッグしたいコード実行時にimportしておくだけ。
例外が起きるとデバッガが起動し停止するので、そのときの変数の値などを表示したり調べると良い。&lt;/p&gt;

&lt;p&gt;不必要に毎回デバッガ起動すると面倒なので、普段はimport行をコメントアウトしておくこと。&lt;/p&gt;

&lt;p&gt;よく使うコマンドは以下のとおり。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;w

&lt;ul&gt;
&lt;li&gt;where. スタックトレースを表示する。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;u

&lt;ul&gt;
&lt;li&gt;up. スタックを一つ上に移動&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;d

&lt;ul&gt;
&lt;li&gt;down. スタックを一つ下に移動&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;l [first, last]

&lt;ul&gt;
&lt;li&gt;list. 現在のソースコード表示。fist, lastを指定可能。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;p [target]

&lt;ul&gt;
&lt;li&gt;print. 変数等を表示。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;c

&lt;ul&gt;
&lt;li&gt;continue. 次のブレークポイントに当たるまで実行&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;s

&lt;ul&gt;
&lt;li&gt;step. 現在の行を実行 (関数の中に入る）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;n

&lt;ul&gt;
&lt;li&gt;next. 現在の行を実行 (関数の中に入らない）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;q

&lt;ul&gt;
&lt;li&gt;quit. デバッガを終了&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>word vectorのような読み込みが重たいやつをWebAPI化して軽量化</title>
      <link>http://blog.hassaku-labs.com/post/word-vector-api/</link>
      <pubDate>Mon, 25 Feb 2019 10:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/word-vector-api/</guid>
      <description>&lt;p&gt;word vectorとかメモリをどデカく使うようなやつは、毎回スクリプトを起動する際に読み込みに時間がかかって辛い。
そういうのは、極力別のプロセスにして、適当にAPIとか生やして連携するようにしておくと楽チンなので良くやるパターン。&lt;/p&gt;

&lt;p&gt;以下は、単語ベクトルを返してくれるAPIを作った例。Flask使うとコードもシンプルに実現出来るので良い。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# coding: utf-8

import numpy as np
import gensim
from flask import Flask, jsonify, request
import json

PRETRAINED_W2V_PATH = &#39;./model.bin&#39;

app = Flask(__name__)
app.config[&#39;JSON_AS_ASCII&#39;] = False

model = gensim.models.KeyedVectors.load_word2vec_format(PRETRAINED_W2V_PATH, binary=True)  # 超時間かかる処理

@app.route(&#39;/word_vector&#39;, methods=[&#39;GET&#39;])
def word_vector():
    word = request.args.get(&#39;word&#39;)
    vector = np.array(model[word]).astype(float).tolist()
    return jsonify({&#39;vector&#39;: vector}), 200


if __name__ == &amp;quot;__main__&amp;quot;:
    app.debug = True
    app.run(host=&#39;0.0.0.0&#39;, port=8888)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のような感じで単語ベクトルの値をjsonで返してくれる。pythonのスクリプトからはrequestsとかで簡単に取得して扱えるはず。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl &amp;quot;http://0.0.0.0:8888/word_vector?word=テスト&amp;quot;
{
  &amp;quot;vector&amp;quot;: [
    0.029713749885559082,
    -0.6024296283721924,
    0.9723357558250427,
    -1.1497808694839478,
    1.3764394521713257,
...

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例えば、連続動作しているようなエージェントシミュレータなんかにも、似たような感じでAPI生やして、インタラクションさせることが出来る。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ターミナル上でシンプルなグリッドワールド</title>
      <link>http://blog.hassaku-labs.com/post/grid-world/</link>
      <pubDate>Fri, 10 Aug 2018 10:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/grid-world/</guid>
      <description>&lt;p&gt;強化学習などでグリッドワールドを使いたいとき、gym-minigridとかpycolabがあるけど、色々いじる必要性もある場合、もっとシンプルなところからはじめたい。
また、リモートのVMインスタンス上などで気軽に動かしたいので、GUIとかも無しで、ターミナル上で動かしたい。&lt;/p&gt;

&lt;p&gt;以下のような感じで、cursesを使ってスクラッチで作っても別に難しいことはなかった。&lt;/p&gt;

&lt;p&gt;こんな感じのやつがターミナル上で動く。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hassaku-labs.com/images/post/grid-world.gif&#34; alt=&#34;grid-world&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import curses
import random
import time
from datetime import datetime

FIELD = [&#39;#################&#39;,
         &#39;#       #       #&#39;,
         &#39;#       #       #&#39;,
         &#39;#       #       #&#39;,
         &#39;#               #&#39;,
         &#39;#       #       #&#39;,
         &#39;######  #########&#39;,
         &#39;#       #       #&#39;,
         &#39;#       #       #&#39;,
         &#39;#               #&#39;,
         &#39;#       #       #&#39;,
         &#39;#       #       #&#39;,
         &#39;#################&#39;]


def draw(screen):
    for row, line in enumerate(FIELD):
        for col, tile in enumerate(line):
            screen.addch(row, col, tile)


def main():
    x = 10
    y = 10

    try:
        screen = curses.initscr()
        screen.nodelay(1)
        curses.curs_set(0)

        while(True):
            action = random.randint(1, 5)
            dx = 0
            dy = 0
            if action == 1:
                dy += 1
            elif action == 2:
                dy -= 1
            elif action == 3:
                dx += 1
            elif action == 4:
                dx -= 1
            elif action == 5:
                pass
            else:
                raise NotImplementedError()

            # check wall
            if FIELD[x + dx][y + dy] != &amp;quot;#&amp;quot;:
                x += dx
                y += dy

            screen.clear()
            draw(screen)
            screen.addch(x, y, &#39;+&#39;) # agent

            screen.addstr(0, 20, datetime.now().strftime(&amp;quot;%Y/%m/%d %H:%M:%S&amp;quot;))
            screen.addstr(1, 20, &#39;a:{} x:{} y:{}&#39;.format(action, x, y))
            screen.refresh()

            # quit
            if(screen.getch() == ord(&#39;q&#39;)):
                break

            time.sleep(0.2)

        curses.endwin()

    except:
        pass

    finally:
        curses.echo()
        curses.endwin()


if __name__ == &#39;__main__&#39;:
    main()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;もしエージェントとインタラクションしたいと思ったら、flaskとかでapi作って状態変えるのが良いと思う。やり方はまた別の機会に。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>単語ベクトルと全結合ニューラルネットワークによる単語連想記憶</title>
      <link>http://blog.hassaku-labs.com/post/associative-word-vector/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/associative-word-vector/</guid>
      <description>

&lt;p&gt;自然言語処理にニューラルネットワークを適用する事例が増えている。
ここでは、従来の部分的に再帰結合をもつようなRNN(LSTM)といった構造ではなく、
(最近はあまり流行っていない）ホップフィールドモデルのような全結合構造のニューラルネットを用いて、
エネルギーポテンシャルの窪み、引き込み領域を有するアトラクタ空間に言語知識を記憶させることを目指す。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hassaku-labs.com/images/post/associative-word-vector/potential.png&#34; alt=&#34;potential&#34; /&gt;&lt;/p&gt;

&lt;p&gt;メリットとして、以下のようなことが挙げられる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;追加学習が容易&lt;/li&gt;
&lt;li&gt;データを大量に学習しなくても汎化性能が高い&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;いくつか想定している内容のうち、今回は単語ベクトルのペアを連想記憶する基本的なタスクを検証する。&lt;/p&gt;

&lt;h1 id=&#34;検証用コード:92074d8141b5d0b357587f68abb31ec5&#34;&gt;検証用コード&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hassaku/associative-word-vector/tree/blog-1&#34;&gt;https://github.com/hassaku/associative-word-vector/tree/blog-1&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;検証内容:92074d8141b5d0b357587f68abb31ec5&#34;&gt;検証内容&lt;/h1&gt;

&lt;p&gt;単語ベクトルは、Github上のREADMEに書いてあるように、東北大学 乾・岡崎研究室で公開されている学習済みのものを利用させて頂いた。&lt;/p&gt;

&lt;p&gt;タスクについては、以下に示すような「鳩」(que) → 「飛ぶ」(target) といった単純な知識を学習させることにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;que target
 鳩   飛ぶ
 牛   走る
 鯉   泳ぐ
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;その後、以下のような未学習の単語(que)に対し、学習済みの知識に基づき、適切な単語(target)を想起出来るかどうかを確かめる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   que target
 カラス   飛ぶ
    馬   走る
    鯛   泳ぐ
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;期待される結果としては、「カラス」も「鳩」と同じく鳥であることから、「飛ぶ」と連想されること。
原理的には、図のような線上のアトラクタに知識を埋め込むことにより、学習済みのもの(que1)に親しい単語ベクトル(que1&amp;rsquo;)であれば、
引き込まれてtarget1を記憶させた平衡点に至ることで想起が実現される。&lt;/p&gt;

&lt;p&gt;今回は原理確認のため、以下のように事前に単語ベクトル間の近さ（コサイン類似度）を確認した上でタスク設定している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  word    カラス      泳ぐ        牛      走る      飛ぶ        馬        鯉        鯛        鳩
カラス  1.000000  0.395338  0.475648  0.162681  0.493993  0.230542  0.406434  0.324465  0.670461
  泳ぐ  0.395338  1.000000  0.166645  0.576415  0.681419  0.162183  0.277283  0.179173  0.385671
    牛  0.475648  0.166645  1.000000  0.083026  0.149580  0.589086  0.559115  0.564100  0.565433
  走る  0.162681  0.576415  0.083026  1.000000  0.508805  0.123983 -0.021091 -0.010774  0.193441
  飛ぶ  0.493993  0.681419  0.149580  0.508805  1.000000  0.110546  0.133639  0.123491  0.422164
    馬  0.230542  0.162183  0.589086  0.123983  0.110546  1.000000  0.251400  0.283276  0.281816
    鯉  0.406434  0.277283  0.559115 -0.021091  0.133639  0.251400  1.000000  0.697661  0.617204
    鯛  0.324465  0.179173  0.564100 -0.010774  0.123491  0.283276  0.697661  1.000000  0.533510
    鳩  0.670461  0.385671  0.565433  0.193441  0.422164  0.281816  0.617204  0.533510  1.000000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;感覚として近そうな単語を選んだつもりでも、意外と単語ベクトルとしては離れていたりする。
そういう場合は、意図しないアトラクタに引き寄せられてしまうため、注意が必要である。
単語ベクトルは、文章中の使われ方を想定して学習されているため、そういうこともあるかとは思うが、
本来は文脈によって、単語間の距離も適切に遠近するはずである。
それについては、次回以降検証することにしたい。&lt;/p&gt;

&lt;p&gt;さて、以下が実際にテストをしてみた結果である。
queがニューラルネットに初期値として与えられる入力パターン、targetが最終的に到達した出力パターン、throughが想起の途中に接近したパターンである。
例えば、「カラス」を初期値とした場合、学習済みの「鳩」に近づいたあと、その連想記憶先である「飛ぶ」を想起していることが分かる。
他の「馬」「鯛」についても、同様の振る舞いを示しつつ、意図した答えを導き出している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;open test
que: カラス target: 飛ぶ through: [&#39;カラス&#39;, &#39;鳩&#39;, &#39;飛ぶ&#39;]
que: 馬     target: 走る through: [&#39;馬&#39;, &#39;牛&#39;, &#39;走る&#39;]
que: 鯛     target: 泳ぐ through: [&#39;鯛&#39;, &#39;鯉&#39;, &#39;泳ぐ&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;さいごに:92074d8141b5d0b357587f68abb31ec5&#34;&gt;さいごに&lt;/h1&gt;

&lt;p&gt;今回は簡単な事例であったものの、まだあまり手を付けられていないような、全結合型神経回路網を用いた言語処理の可能性を検証した。
全結合型の特徴でもあるエネルギー的な安定状態に記憶を埋め込むことにより、人のように強力な汎化能力をもった記憶を、安定して追加学習できる。
次回以降、実装の詳細や現実的な用途のために必要な、文脈の考慮などについて紹介していきたい。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ターミナル上で１行の簡易グラフ</title>
      <link>http://blog.hassaku-labs.com/post/ascii-simple-plot/</link>
      <pubDate>Mon, 23 Apr 2018 00:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/ascii-simple-plot/</guid>
      <description>&lt;p&gt;データ処理などしていると、処理中の状況を確認するのに、数値や文字列よりもグラフの方が適していることが多い。
ただ、そのためだけにGUIなどを用意するのは大変だし、出来ればターミナル上で表示したい。
というわけで、ログなど混ぜて、以下のような感じで、簡易的にグラフ描くと便利。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat simple_plot.py

# coding: utf-8

import numpy as np

TICKS = u&#39;_▁▂▃▄▅▆▇█&#39;

def ascii_plot(ints, max_range=None, min_range=0, width=40):
    assert len(ints) &amp;gt;= width

    ints = np.array(ints, dtype=int)
    ints = ints[:int(len(ints)/width)*width]
    ints = np.nansum(np.reshape(ints, (int(len(ints)/width), width)).T, axis=1)

    if not max_range:
        max_range = max(ints)
    if not min_range:
        min_range = min(ints)

    step_range = max_range - min_range
    step = (step_range / float(len(TICKS) - 1)) or 1
    return u&#39;&#39;.join(TICKS[int(round((i - min_range) / step))] for i in ints)


if __name__ == &amp;quot;__main__&amp;quot;:
   print(ascii_plot(range(10) + range(10, 0, -1), width=20))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ python simple_plot.py
_▁▂▂▃▄▅▆▆▇█▇▆▆▅▄▃▂▂▁
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>pythonの各種使い方をオフラインで確認する方法</title>
      <link>http://blog.hassaku-labs.com/post/python-offline-help/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/python-offline-help/</guid>
      <description>

&lt;p&gt;インターネットから隔離されていたりや書籍が持ち込みできないような環境で、プログラミングをすることがあった。
こういうときのために、各種ライブラリの使い方などをオフラインでも確認できるようにしておくと良い。&lt;/p&gt;

&lt;h2 id=&#34;各種ライブラリのヘルプ確認の仕方:98bf9ba98ae68fda7629e698d07e5dba&#34;&gt;各種ライブラリのヘルプ確認の仕方&lt;/h2&gt;

&lt;p&gt;例えば、scikit-learnのkmeansクラスタリングの使い方を調べたいとき。
一番上から順に探していく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; import sklearn
&amp;gt; help(sklearn)
...
PACKAGE CONTENTS
    ...
    cluster (package)
...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; import sklearn.cluster
&amp;gt; help(sklearn.cluster)
...
PACKAGE CONTENTS
    ...
    k_means_
...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; import sklearn.cluster.k_means_
&amp;gt; help(sklearn.cluster.k_means_)
class KMeans(sklearn.base.BaseEstimator, sklearn.base.ClusterMixin, sklearn.base.TransformerMixin)
     |  K-Means clustering
     |
     |  Parameters
...
目的の使い方にたどり着いた
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;jupyter-notebook上でのやり方:98bf9ba98ae68fda7629e698d07e5dba&#34;&gt;jupyter notebook上でのやり方&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; import pandas as pd
&amp;gt; pd.read_csv?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下部にヘルプ用のウインドウが別途表示されるので、若干見やすい（？）&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slackのメッセージ収集</title>
      <link>http://blog.hassaku-labs.com/post/slack-mining/</link>
      <pubDate>Tue, 23 Jan 2018 00:00:00 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/slack-mining/</guid>
      <description>

&lt;p&gt;Slackに投稿されたメッセージを収集する方法についてのメモ&lt;/p&gt;

&lt;h2 id=&#34;データexport:dab3dd72a9f7b423459ecf8af70c80de&#34;&gt;データexport&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://xxxx.slack.com/services/export&#34;&gt;https://xxxx.slack.com/services/export&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;exportが完了すると、slack上でbotから通知くる&lt;/p&gt;

&lt;h2 id=&#34;ユーザid取得:dab3dd72a9f7b423459ecf8af70c80de&#34;&gt;ユーザID取得&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ curl https://slack.com/api/users.list\?token\=YOUR_SLACK_TOKEN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最新のSlack Token取得方法は色々記事が挙がっているのでググること&lt;/p&gt;

&lt;h2 id=&#34;一ヶ月のユーザの発言を収集する:dab3dd72a9f7b423459ecf8af70c80de&#34;&gt;一ヶ月のユーザの発言を収集する&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;$ cat show_messages.rb

require &#39;json&#39;

user = &amp;quot;USER_ID&amp;quot;
year = 2016
month = 2
days = 29

days.times do |day|
  date = &amp;quot;%d-%2d-%02d&amp;quot; % (year, month, day + 1)
  export_file = &amp;quot;./#{date}.json&amp;quot;
  next unless File.exist?(export_file)
  puts &amp;quot;\n----- #{date} -----&amp;quot;

  json_data = open(export_file) do |io|
    JSON.load(io)
  end

  json_data.each do |json|
    puts &amp;quot;#{Time.at(json[&#39;ts&#39;].to_i)}: #{json[&#39;text&#39;].gsub(/\n+/, &#39; &#39;)}&amp;quot; if json[&amp;quot;user&amp;quot;] == user
  end
end

$ ruby show_messages.rb
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>partial AUCでprecision重視の評価</title>
      <link>http://blog.hassaku-labs.com/post/partial-auc/</link>
      <pubDate>Sat, 23 Dec 2017 00:59:39 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/partial-auc/</guid>
      <description>&lt;p&gt;機械学習の判別器を評価する際、F値やAUCはよく使われていると思います。
しかしながら、実応用の分野によっては、検出出来ないこと(false negative)よりも、誤検出(false positive)の方が問題視されることがよくあります。
そういったprecision重視にしたいケースで使える指標がpartial AUCです。
一般的には、false positiveに制約をもたせて用いるようです。AUCの面積を求める際に、そのfalse positive rateの下限値以上の部分のみ使います。&lt;/p&gt;

&lt;p&gt;簡単に実装するため、scikit learnのaucのコードをオーバーライドして使っています。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import numpy as np
from sklearn.metrics import roc_auc_score, roc_curve, auc
from sklearn.metrics.base import _average_binary_score

# method overriding
def roc_auc_score(y_true, y_score, average=&amp;quot;macro&amp;quot;, sample_weight=None, max_fpr=None):
    def _binary_roc_auc_score(y_true, y_score, sample_weight=None, max_fpr=max_fpr):
        fpr, tpr, tresholds = roc_curve(y_true, y_score, sample_weight=sample_weight)

        if max_fpr:
            idx = np.where(fpr &amp;lt;= max_fpr)[0]

            idx_last = idx.max()
            idx_next = idx_last + 1
            xc = [fpr[idx_last], fpr[idx_next]]
            yc = [tpr[idx_last], tpr[idx_next]]
            tpr = np.r_[tpr[idx], np.interp(max_fpr, xc, yc)]
            fpr = np.r_[fpr[idx], max_fpr]
            partial_roc = auc(fpr, tpr, reorder=True)

            # standardize result to lie between 0.5 and 1
            min_area = max_fpr**2/2
            max_area = max_fpr
            return 0.5*(1+(partial_roc-min_area)/(max_area-min_area))

        return auc(fpr, tpr, reorder=True)

    return _average_binary_score(_binary_roc_auc_score, y_true, y_score, average, sample_weight=sample_weight)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のような感じで試してみると、AUCが同じスコアであっても、precisionが高い方がpAUCでは比較的高い値になることが分かります。
よって、pAUCを指標に学習やパラメータチューニングを行えば、precision重視のものが出来上がります。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import matplotlib.pylab as plt
import numpy as np

y_true = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0])
y_pred_each_fp = {
    &amp;quot;many&amp;quot;: np.array([0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]),
    &amp;quot;few&amp;quot;: np.array([1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]),
    &amp;quot;no&amp;quot;: np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]),
}


MAX_FALSE_POSITIVE_RATE = 0.3

plt.figure(figsize=(17, 5))
for fi, (fp_type, y_pred) in enumerate(y_pred_each_fp.items()):
    plt.subplot(1, 3, fi+1)
    fpr, tpr, _ = roc_curve(y_true, y_pred)
    plt.plot(fpr, tpr, color=&#39;r&#39;, lw=2)
    plt.plot([0, 1], [0, 1], color=&#39;k&#39;, lw=1, linestyle=&#39;--&#39;)
    plt.plot([MAX_FALSE_POSITIVE_RATE, MAX_FALSE_POSITIVE_RATE], [0, 1], color=&#39;k&#39;, lw=1, linestyle=&#39;-.&#39;)
    plt.xlabel(&#39;false positive rate&#39;)
    plt.ylabel(&#39;true positive rate&#39;)
    plt.title(&amp;quot;{fp_type} false positives (auc:{auc:1.2f}  pauc:{pauc:1.2f})&amp;quot;.format(fp_type=fp_type,
        auc=roc_auc_score(y_true, y_pred), pauc=roc_auc_score(y_true, y_pred, max_fpr=MAX_FALSE_POSITIVE_RATE)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hassaku-labs.com/images/post/pauc/pauc.png&#34; alt=&#34;pauc&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>自分流論文メモのやり方</title>
      <link>http://blog.hassaku-labs.com/post/paper-management/</link>
      <pubDate>Fri, 22 Dec 2017 17:17:30 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/paper-management/</guid>
      <description>&lt;p&gt;普段から興味ある分野について、arXivを漁っている人多いと思うのですが、やはり手っ取り早く内容を俯瞰するには、abstractが日本語になっている方が負荷が少ないと思います。日本語の概要を一瞬見て、ちゃんと読んだ方がいいかどうか判断する感じです。&lt;/p&gt;

&lt;p&gt;自分は以下のような感じで、arxivのidを貼り付けると、自動でタイトルとか概要を取得して、隣に翻訳も表示してくれるようなスプレッドシートを用意しているのですが、便利なので公開したいと思います。ついでに、実装が公開されていればそのリンクや、簡単な感想なんかもメモするようにしています。&lt;/p&gt;

&lt;iframe src=&#34;https://docs.google.com/spreadsheets/d/e/2PACX-1vRPeZS-GHkCUm6yyhMTXiWfUsbrxa0a_mmNYWygCw1oDuyU7G_v-P2Hhn7iFfT1_HeZFB8NfRJHeIfR/pubhtml?gid=0&amp;amp;single=true&amp;amp;widget=true&amp;amp;headers=false&#34; width=&#34;800&#34; height=&#34;500&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;以下から適当にコピーして頂ければ、使えるかと思います。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/19AHvw82bFWivJtoVTohvUDs-uMuhyH0Dw0IzIpvviog&#34;&gt;https://docs.google.com/spreadsheets/d/19AHvw82bFWivJtoVTohvUDs-uMuhyH0Dw0IzIpvviog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;誰かのお役に立てれば幸いです。。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>hyperoptでパラメータサーチ</title>
      <link>http://blog.hassaku-labs.com/post/hyperopt/</link>
      <pubDate>Sat, 04 Mar 2017 04:08:51 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/hyperopt/</guid>
      <description>

&lt;p&gt;機械学習におけるモデルのハイパーパラメータ探索は、その後のモデル評価を正当に行うことにも繋がる、重要な作業です。
近年ではRandom SearchやGrid Search、GA等の各種最適化手法よりも、色々と優れた手法が提案されているらしく、
手軽に使えるようなライブラリも整備されています。
パラメータ探索技術というと、応用範囲が広く、効果が見えやすいため、手軽に使えて効率的な手法があれば、積極的に使っていきたいところです。
その中でもhyperoptというライブラリが、kaggleとかでよく使われているという話を見かけて、試しに使ってみました。&lt;/p&gt;

&lt;p&gt;中身については、色々Blogや論文が見つかるのですが、
Bayesian Optimization -&amp;gt; Sequential Model-based Algorithm Configuration (SMAC) -&amp;gt; Tree-structured Parzen Estimator (TPE)
のように進化してきたTPEという手法が使われているようです。
Bayesian Optimizationのアプローチは、直感的にも効率良さそうなので、その進化系なら期待できます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://hyperopt.github.io/hyperopt/&#34;&gt;Hyperopt&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;簡単な使い方:3ef796ded5fdc2a18d77f9e19d0b06e3&#34;&gt;簡単な使い方&lt;/h2&gt;

&lt;p&gt;以下のような感じで、簡単に記述出来て、手軽に取り入れられそうです。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python
# encoding: utf-8

import os
import sys

import matplotlib.pyplot as plt
import numpy as np
from hyperopt import fmin, tpe, hp, Trials

# パラメータの探索範囲。指定方法は離散値や連続値などに応じて色々ある。
# https://github.com/hyperopt/hyperopt/wiki/FMin#21-parameter-expressions
hyperopt_parameters = { &#39;x&#39;: hp.uniform(&#39;x&#39;, -30, 30) }

# 最小化したい目的関数。正解との誤差とか。
def objective(args):
    return np.sin(args[&#39;x&#39;]) / args[&#39;x&#39;]

# 探索中の進行状況を記録
trials = Trials()

# パラメータサーチの実行
best = fmin(objective,  hyperopt_parameters, algo=tpe.suggest, max_evals=300, trials=trials)

# 目的関数を最小にするパラメータ
print best
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;パラメータサーチの様子を表示:3ef796ded5fdc2a18d77f9e19d0b06e3&#34;&gt;パラメータサーチの様子を表示&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;# 上記コードの続き

x_hisotry = np.ravel([t[&#39;misc&#39;][&#39;vals&#39;][&#39;x&#39;] for t in trials.trials])
objective_history = trials.losses()

fig = plt.figure(figsize=(16, 8))
cm = plt.get_cmap(&#39;jet&#39;)

PLOT_NUM = 5

for i, hist_num in enumerate(np.linspace(50, 300, PLOT_NUM)):
    cmap_cycle = [cm(1. * h/ (hist_num - 1)) for h in range(int(hist_num) - 1)]

    ax = plt.subplot(2, PLOT_NUM, i + 1)
    ax.set_color_cycle(cmap_cycle)
    ax.plot(np.arange(-30, 30, 0.1), function(np.arange(-30, 30, 0.1)), alpha=0.2)
    for j in range(int(hist_num)  - 1):
        ax.plot(x_hisotry[j], objective_history[j], &#39;.&#39;)
    ax.set_title(&#39;times: {times}&#39;.format(times=int(hist_num)))
    ax.set_ylim([np.min(objective_history) - 0.1, np.max(objective_history) + 0.1])
    ax.set_xlim([-30, 30])
    if i == 0:
        ax.set_ylabel(&#39;y&#39;)

    plt.subplot(2, PLOT_NUM, PLOT_NUM + i + 1)
    plt.hist(x_hisotry[:hist_num], bins=50)
    if i == 0:
        plt.ylabel(&#39;histogram of x&#39;)
    plt.xlabel(&#39;x&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hassaku-labs.com/images/post/hyperopt/hyperopt.png&#34; alt=&#34;hyperopt&#34; /&gt;&lt;/p&gt;

&lt;p&gt;右に進むに連れて、パラメータ探索が進んでいく様子を表しています。
上段の図が、目的関数と探索点の描画です。x=0の点が求めたいパラメータとなります。
下段の図が、各探索点のヒストグラムを描画しているのですが、探索が進むにつれて、
目標のパラメータ付近を効率的に探索している様子が分かります。&lt;/p&gt;

&lt;h4 id=&#34;追記:3ef796ded5fdc2a18d77f9e19d0b06e3&#34;&gt;追記&lt;/h4&gt;

&lt;p&gt;バンディットベースのものが出たらしい。使い方もhyperopt同様に簡単そうなので、パラメータチューニング時の候補にしたい。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/zygmuntz/hyperband&#34;&gt;Hyperband&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>インスタンスを表す文字列を分かりやすくする</title>
      <link>http://blog.hassaku-labs.com/post/class-repr/</link>
      <pubDate>Sat, 04 Mar 2017 04:07:38 +0900</pubDate>
      
      <guid>http://blog.hassaku-labs.com/post/class-repr/</guid>
      <description>

&lt;p&gt;ログとかにインスタンスの内容をダンプしたりするとき、つい適当にprintとかlogger.debugしても、
標準では、インスタンスの内容をスマートに分かりやすく表示してくれたりはしないようです。&lt;/p&gt;

&lt;p&gt;そのため、デバッグをしやすくするためにも、以下のような感じで__repr__をオーバーライドしておくと、
分かりやすくなって便利だったりします。&lt;/p&gt;

&lt;h2 id=&#34;reprを定義しない場合:9c4edd90300eaacc62e25ae2f1faec5e&#34;&gt;reprを定義しない場合&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;class MyClass(object):
  def __init__(self):
    self.attr1 = 123
    self.attr2 = 456

mc = MyClass()
print(mc)  # =&amp;gt; &amp;lt;__main__.MyClass object at 0xXXXXXXXXXX&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;reprを定義する場合:9c4edd90300eaacc62e25ae2f1faec5e&#34;&gt;reprを定義する場合&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;class MyClass(object):
  def __init__(self):
    self.attr1 = 123
    self.attr2 = 456

  def __repr__(self):
    return &amp;quot;, &amp;quot;.join(&amp;quot;%s: %s&amp;quot; % item for item in vars(self).items())

mc = MyClass()
print(mc)  # =&amp;gt; attr2: 456, attr1: 123
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ちょっとしたTipsでした。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>