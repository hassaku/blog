<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on hassaku&#39;s blog</title>
    <link>https://blog.hassaku-labs.com/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on hassaku&#39;s blog</description>
    <generator>Hugo</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 04 Mar 2017 04:08:51 +0900</lastBuildDate>
    <atom:link href="https://blog.hassaku-labs.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>hyperoptでパラメータサーチ</title>
      <link>https://blog.hassaku-labs.com/post/hyperopt/</link>
      <pubDate>Sat, 04 Mar 2017 04:08:51 +0900</pubDate>
      <guid>https://blog.hassaku-labs.com/post/hyperopt/</guid>
      <description>&lt;p&gt;機械学習におけるモデルのハイパーパラメータ探索は、その後のモデル評価を正当に行うことにも繋がる、重要な作業です。&#xA;近年ではRandom SearchやGrid Search、GA等の各種最適化手法よりも、色々と優れた手法が提案されているらしく、&#xA;手軽に使えるようなライブラリも整備されています。&#xA;パラメータ探索技術というと、応用範囲が広く、効果が見えやすいため、手軽に使えて効率的な手法があれば、積極的に使っていきたいところです。&#xA;その中でもhyperoptというライブラリが、kaggleとかでよく使われているという話を見かけて、試しに使ってみました。&lt;/p&gt;&#xA;&lt;p&gt;中身については、色々Blogや論文が見つかるのですが、&#xA;Bayesian Optimization -&amp;gt; Sequential Model-based Algorithm Configuration (SMAC) -&amp;gt; Tree-structured Parzen Estimator (TPE)&#xA;のように進化してきたTPEという手法が使われているようです。&#xA;Bayesian Optimizationのアプローチは、直感的にも効率良さそうなので、その進化系なら期待できます。&lt;/p&gt;&#xA;&lt;p&gt;[Hyperopt]&#xA;(&lt;a href=&#34;http://hyperopt.github.io/hyperopt/&#34;&gt;http://hyperopt.github.io/hyperopt/&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;h2 id=&#34;簡単な使い方&#34;&gt;簡単な使い方&lt;/h2&gt;&#xA;&lt;p&gt;以下のような感じで、簡単に記述出来て、手軽に取り入れられそうです。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#!/usr/bin/env python&#xA;# encoding: utf-8&#xA;&#xA;import os&#xA;import sys&#xA;&#xA;import matplotlib.pyplot as plt&#xA;import numpy as np&#xA;from hyperopt import fmin, tpe, hp, Trials&#xA;&#xA;# パラメータの探索範囲。指定方法は離散値や連続値などに応じて色々ある。&#xA;# https://github.com/hyperopt/hyperopt/wiki/FMin#21-parameter-expressions&#xA;hyperopt_parameters = { &amp;#39;x&amp;#39;: hp.uniform(&amp;#39;x&amp;#39;, -30, 30) }&#xA;&#xA;# 最小化したい目的関数。正解との誤差とか。&#xA;def objective(args):&#xA;    return np.sin(args[&amp;#39;x&amp;#39;]) / args[&amp;#39;x&amp;#39;]&#xA;&#xA;# 探索中の進行状況を記録&#xA;trials = Trials()&#xA;&#xA;# パラメータサーチの実行&#xA;best = fmin(objective,  hyperopt_parameters, algo=tpe.suggest, max_evals=300, trials=trials)&#xA;&#xA;# 目的関数を最小にするパラメータ&#xA;print best&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;パラメータサーチの様子を表示&#34;&gt;パラメータサーチの様子を表示&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# 上記コードの続き&#xA;&#xA;x_hisotry = np.ravel([t[&amp;#39;misc&amp;#39;][&amp;#39;vals&amp;#39;][&amp;#39;x&amp;#39;] for t in trials.trials])&#xA;objective_history = trials.losses()&#xA;&#xA;fig = plt.figure(figsize=(16, 8))&#xA;cm = plt.get_cmap(&amp;#39;jet&amp;#39;)&#xA;&#xA;PLOT_NUM = 5&#xA;&#xA;for i, hist_num in enumerate(np.linspace(50, 300, PLOT_NUM)):&#xA;    cmap_cycle = [cm(1. * h/ (hist_num - 1)) for h in range(int(hist_num) - 1)]&#xA;&#xA;    ax = plt.subplot(2, PLOT_NUM, i + 1)&#xA;    ax.set_color_cycle(cmap_cycle)&#xA;    ax.plot(np.arange(-30, 30, 0.1), function(np.arange(-30, 30, 0.1)), alpha=0.2)&#xA;    for j in range(int(hist_num)  - 1):&#xA;        ax.plot(x_hisotry[j], objective_history[j], &amp;#39;.&amp;#39;)&#xA;    ax.set_title(&amp;#39;times: {times}&amp;#39;.format(times=int(hist_num)))&#xA;    ax.set_ylim([np.min(objective_history) - 0.1, np.max(objective_history) + 0.1])&#xA;    ax.set_xlim([-30, 30])&#xA;    if i == 0:&#xA;        ax.set_ylabel(&amp;#39;y&amp;#39;)&#xA;&#xA;    plt.subplot(2, PLOT_NUM, PLOT_NUM + i + 1)&#xA;    plt.hist(x_hisotry[:hist_num], bins=50)&#xA;    if i == 0:&#xA;        plt.ylabel(&amp;#39;histogram of x&amp;#39;)&#xA;    plt.xlabel(&amp;#39;x&amp;#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://blog.hassaku-labs.com/images/post/hyperopt/hyperopt.png&#34; alt=&#34;hyperopt&#34;&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
